import math
a = 1.0
b = -5.0
c = 6.0

discriminant = b**2 - 4*a*c

if discriminant > 0:
    root1 = (-b + math.sqrt(discriminant)) / (2 * a)
    root2 = (-b - math.sqrt(discriminant)) / (2 * a)
    print(f"Roots: {root1:.2f} and {root2:.2f}")
elif discriminant == 0:
    root = -b / (2 * a)
    print(f"Root: {root:.2f}")
else:
    print("No real roots.")
